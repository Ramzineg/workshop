{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0AWVSPHpmhb"
      },
      "source": [
        "### 1. Keras Sequential model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RNl__m9Npmhg"
      },
      "outputs": [],
      "source": [
        "\"import librairies\"\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEy_Ze0opmhi"
      },
      "source": [
        "#### 1.1. Read in the data and explore:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "seNNv0uipmhk"
      },
      "outputs": [],
      "source": [
        "# Read.\n",
        "df=pd.read_csv('/content/data_boston.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GbeXc-Y7pmhl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5e5ff5ef-179f-49d7-d3ef-ce062a71c625"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
              "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
              "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
              "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
              "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
              "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
              "\n",
              "        B  LSTAT  PRICE  \n",
              "0  396.90   4.98   24.0  \n",
              "1  396.90   9.14   21.6  \n",
              "2  392.83   4.03   34.7  \n",
              "3  394.63   2.94   33.4  \n",
              "4  396.90   5.33   36.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c078f7f-2ac4-4dfc-8b4b-980869558340\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c078f7f-2ac4-4dfc-8b4b-980869558340')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c078f7f-2ac4-4dfc-8b4b-980869558340 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c078f7f-2ac4-4dfc-8b4b-980869558340');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# View.\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bxXCLnRNpmhm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "7141f8d7-ef4c-4c69-f60c-7eae81d2d021"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       CRIM    ZN     INDUS  CHAS       NOX        RM       AGE       DIS  \\\n",
              "0  0.000000  0.18  0.067815   0.0  0.314815  0.577505  0.641607  0.269203   \n",
              "1  0.000236  0.00  0.242302   0.0  0.172840  0.547998  0.782698  0.348962   \n",
              "2  0.000236  0.00  0.242302   0.0  0.172840  0.694386  0.599382  0.348962   \n",
              "3  0.000293  0.00  0.063050   0.0  0.150206  0.658555  0.441813  0.448545   \n",
              "4  0.000705  0.00  0.063050   0.0  0.150206  0.687105  0.528321  0.448545   \n",
              "\n",
              "        RAD       TAX   PTRATIO         B     LSTAT     PRICE  \n",
              "0  0.000000  0.208015  0.287234  1.000000  0.089680  0.422222  \n",
              "1  0.043478  0.104962  0.553191  1.000000  0.204470  0.368889  \n",
              "2  0.043478  0.104962  0.553191  0.989737  0.063466  0.660000  \n",
              "3  0.086957  0.066794  0.648936  0.994276  0.033389  0.631111  \n",
              "4  0.086957  0.066794  0.648936  1.000000  0.099338  0.693333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6198f7b9-6b74-4373-ae78-c0ebd0c82264\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.067815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.314815</td>\n",
              "      <td>0.577505</td>\n",
              "      <td>0.641607</td>\n",
              "      <td>0.269203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208015</td>\n",
              "      <td>0.287234</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.089680</td>\n",
              "      <td>0.422222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.242302</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172840</td>\n",
              "      <td>0.547998</td>\n",
              "      <td>0.782698</td>\n",
              "      <td>0.348962</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.104962</td>\n",
              "      <td>0.553191</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.204470</td>\n",
              "      <td>0.368889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.242302</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172840</td>\n",
              "      <td>0.694386</td>\n",
              "      <td>0.599382</td>\n",
              "      <td>0.348962</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.104962</td>\n",
              "      <td>0.553191</td>\n",
              "      <td>0.989737</td>\n",
              "      <td>0.063466</td>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000293</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.063050</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150206</td>\n",
              "      <td>0.658555</td>\n",
              "      <td>0.441813</td>\n",
              "      <td>0.448545</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.066794</td>\n",
              "      <td>0.648936</td>\n",
              "      <td>0.994276</td>\n",
              "      <td>0.033389</td>\n",
              "      <td>0.631111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000705</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.063050</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150206</td>\n",
              "      <td>0.687105</td>\n",
              "      <td>0.528321</td>\n",
              "      <td>0.448545</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.066794</td>\n",
              "      <td>0.648936</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.099338</td>\n",
              "      <td>0.693333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6198f7b9-6b74-4373-ae78-c0ebd0c82264')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6198f7b9-6b74-4373-ae78-c0ebd0c82264 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6198f7b9-6b74-4373-ae78-c0ebd0c82264');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Scale the X data use min max scaller and fit transform.\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler= MinMaxScaler()\n",
        "scaler.fit(df)\n",
        "scaler_data=pd.DataFrame(scaler.transform(df),columns=df.columns)\n",
        "scaler_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qIF0bak-pmhn"
      },
      "outputs": [],
      "source": [
        "# Spit the data into training and testing.\n",
        "x=scaler_data.loc[:,scaler_data.columns !='PRICE']\n",
        "y=scaler_data['PRICE']\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.8,test_size=0.2,random_state=42)\n",
        "X_model, X_valid, Y_model, Y_valid = train_test_split(x_train, y_train, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UahCpbZpmho"
      },
      "source": [
        "#### 1.2. Define a Sequential model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2P6U_OGWpmho"
      },
      "outputs": [],
      "source": [
        "# Add layers on a Sequential object.\n",
        "my_model1 = Sequential()\n",
        "n_vars=x.shape[1]\n",
        "my_model1.add(Dense(input_dim = n_vars, units = 1, activation=\"linear\"))    # Add a output layer for linear regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UAqroOnapmhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b3496c-ec1e-40a7-d4d2-47a959220c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 14        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Summary of the model.\n",
        "my_model1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHzrH1g9pmhp"
      },
      "source": [
        "#### 1.3. Define the hyperparameters and optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h7trkJzVpmhq"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters.\n",
        "n_epochs = 200\n",
        "batch_size =64\n",
        "learn_rate =0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wWDc3vCepmhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a969db-2aeb-4512-ff38-03cba64fb990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# Define the optimizer and then compile.\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "adamm= Adam(lr=learn_rate)\n",
        "my_model1.compile(loss='MSE', optimizer=adamm, metrics=[\"MSE\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff1acLDFpmhr"
      },
      "source": [
        "#### 1.4. Train the model and visualize the history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K8VyJaYMpmhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffca0cb9-b9c8-45a3-d85e-34227f9e956d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "6/6 [==============================] - 1s 48ms/step - loss: 0.9503 - MSE: 0.9503 - val_loss: 0.8727 - val_MSE: 0.8727\n",
            "Epoch 2/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8932 - MSE: 0.8932 - val_loss: 0.8194 - val_MSE: 0.8194\n",
            "Epoch 3/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8395 - MSE: 0.8395 - val_loss: 0.7696 - val_MSE: 0.7696\n",
            "Epoch 4/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7899 - MSE: 0.7899 - val_loss: 0.7225 - val_MSE: 0.7225\n",
            "Epoch 5/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.7430 - MSE: 0.7430 - val_loss: 0.6780 - val_MSE: 0.6780\n",
            "Epoch 6/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6990 - MSE: 0.6990 - val_loss: 0.6375 - val_MSE: 0.6375\n",
            "Epoch 7/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6589 - MSE: 0.6589 - val_loss: 0.6002 - val_MSE: 0.6002\n",
            "Epoch 8/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6227 - MSE: 0.6227 - val_loss: 0.5663 - val_MSE: 0.5663\n",
            "Epoch 9/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5887 - MSE: 0.5887 - val_loss: 0.5352 - val_MSE: 0.5352\n",
            "Epoch 10/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5587 - MSE: 0.5587 - val_loss: 0.5058 - val_MSE: 0.5058\n",
            "Epoch 11/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5297 - MSE: 0.5297 - val_loss: 0.4791 - val_MSE: 0.4791\n",
            "Epoch 12/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5034 - MSE: 0.5034 - val_loss: 0.4546 - val_MSE: 0.4546\n",
            "Epoch 13/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4791 - MSE: 0.4791 - val_loss: 0.4313 - val_MSE: 0.4313\n",
            "Epoch 14/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4575 - MSE: 0.4575 - val_loss: 0.4109 - val_MSE: 0.4109\n",
            "Epoch 15/150\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4372 - MSE: 0.4372 - val_loss: 0.3928 - val_MSE: 0.3928\n",
            "Epoch 16/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4204 - MSE: 0.4204 - val_loss: 0.3775 - val_MSE: 0.3775\n",
            "Epoch 17/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4051 - MSE: 0.4051 - val_loss: 0.3623 - val_MSE: 0.3623\n",
            "Epoch 18/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3900 - MSE: 0.3900 - val_loss: 0.3474 - val_MSE: 0.3474\n",
            "Epoch 19/150\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3755 - MSE: 0.3755 - val_loss: 0.3332 - val_MSE: 0.3332\n",
            "Epoch 20/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3615 - MSE: 0.3615 - val_loss: 0.3200 - val_MSE: 0.3200\n",
            "Epoch 21/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3490 - MSE: 0.3490 - val_loss: 0.3089 - val_MSE: 0.3089\n",
            "Epoch 22/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3384 - MSE: 0.3384 - val_loss: 0.2989 - val_MSE: 0.2989\n",
            "Epoch 23/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3283 - MSE: 0.3283 - val_loss: 0.2895 - val_MSE: 0.2895\n",
            "Epoch 24/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3188 - MSE: 0.3188 - val_loss: 0.2808 - val_MSE: 0.2808\n",
            "Epoch 25/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3101 - MSE: 0.3101 - val_loss: 0.2724 - val_MSE: 0.2724\n",
            "Epoch 26/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3018 - MSE: 0.3018 - val_loss: 0.2649 - val_MSE: 0.2649\n",
            "Epoch 27/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2945 - MSE: 0.2945 - val_loss: 0.2579 - val_MSE: 0.2579\n",
            "Epoch 28/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2873 - MSE: 0.2873 - val_loss: 0.2509 - val_MSE: 0.2509\n",
            "Epoch 29/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2801 - MSE: 0.2801 - val_loss: 0.2441 - val_MSE: 0.2441\n",
            "Epoch 30/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2731 - MSE: 0.2731 - val_loss: 0.2373 - val_MSE: 0.2373\n",
            "Epoch 31/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2662 - MSE: 0.2662 - val_loss: 0.2309 - val_MSE: 0.2309\n",
            "Epoch 32/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2598 - MSE: 0.2598 - val_loss: 0.2250 - val_MSE: 0.2250\n",
            "Epoch 33/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2535 - MSE: 0.2535 - val_loss: 0.2193 - val_MSE: 0.2193\n",
            "Epoch 34/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2475 - MSE: 0.2475 - val_loss: 0.2139 - val_MSE: 0.2139\n",
            "Epoch 35/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2419 - MSE: 0.2419 - val_loss: 0.2091 - val_MSE: 0.2091\n",
            "Epoch 36/150\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2367 - MSE: 0.2367 - val_loss: 0.2043 - val_MSE: 0.2043\n",
            "Epoch 37/150\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2316 - MSE: 0.2316 - val_loss: 0.1996 - val_MSE: 0.1996\n",
            "Epoch 38/150\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2265 - MSE: 0.2265 - val_loss: 0.1952 - val_MSE: 0.1952\n",
            "Epoch 39/150\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2218 - MSE: 0.2218 - val_loss: 0.1907 - val_MSE: 0.1907\n",
            "Epoch 40/150\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2171 - MSE: 0.2171 - val_loss: 0.1868 - val_MSE: 0.1868\n",
            "Epoch 41/150\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2126 - MSE: 0.2126 - val_loss: 0.1830 - val_MSE: 0.1830\n",
            "Epoch 42/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2086 - MSE: 0.2086 - val_loss: 0.1794 - val_MSE: 0.1794\n",
            "Epoch 43/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2045 - MSE: 0.2045 - val_loss: 0.1759 - val_MSE: 0.1759\n",
            "Epoch 44/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2005 - MSE: 0.2005 - val_loss: 0.1723 - val_MSE: 0.1723\n",
            "Epoch 45/150\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1964 - MSE: 0.1964 - val_loss: 0.1688 - val_MSE: 0.1688\n",
            "Epoch 46/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1925 - MSE: 0.1925 - val_loss: 0.1655 - val_MSE: 0.1655\n",
            "Epoch 47/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1888 - MSE: 0.1888 - val_loss: 0.1623 - val_MSE: 0.1623\n",
            "Epoch 48/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1851 - MSE: 0.1851 - val_loss: 0.1590 - val_MSE: 0.1590\n",
            "Epoch 49/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1813 - MSE: 0.1813 - val_loss: 0.1557 - val_MSE: 0.1557\n",
            "Epoch 50/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1777 - MSE: 0.1777 - val_loss: 0.1526 - val_MSE: 0.1526\n",
            "Epoch 51/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1742 - MSE: 0.1742 - val_loss: 0.1497 - val_MSE: 0.1497\n",
            "Epoch 52/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1710 - MSE: 0.1710 - val_loss: 0.1469 - val_MSE: 0.1469\n",
            "Epoch 53/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1677 - MSE: 0.1677 - val_loss: 0.1440 - val_MSE: 0.1440\n",
            "Epoch 54/150\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1644 - MSE: 0.1644 - val_loss: 0.1412 - val_MSE: 0.1412\n",
            "Epoch 55/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1613 - MSE: 0.1613 - val_loss: 0.1385 - val_MSE: 0.1385\n",
            "Epoch 56/150\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1582 - MSE: 0.1582 - val_loss: 0.1359 - val_MSE: 0.1359\n",
            "Epoch 57/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1552 - MSE: 0.1552 - val_loss: 0.1333 - val_MSE: 0.1333\n",
            "Epoch 58/150\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1523 - MSE: 0.1523 - val_loss: 0.1307 - val_MSE: 0.1307\n",
            "Epoch 59/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1492 - MSE: 0.1492 - val_loss: 0.1281 - val_MSE: 0.1281\n",
            "Epoch 60/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1461 - MSE: 0.1461 - val_loss: 0.1254 - val_MSE: 0.1254\n",
            "Epoch 61/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1430 - MSE: 0.1430 - val_loss: 0.1228 - val_MSE: 0.1228\n",
            "Epoch 62/150\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1401 - MSE: 0.1401 - val_loss: 0.1204 - val_MSE: 0.1204\n",
            "Epoch 63/150\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1373 - MSE: 0.1373 - val_loss: 0.1181 - val_MSE: 0.1181\n",
            "Epoch 64/150\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1347 - MSE: 0.1347 - val_loss: 0.1159 - val_MSE: 0.1159\n",
            "Epoch 65/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1322 - MSE: 0.1322 - val_loss: 0.1138 - val_MSE: 0.1138\n",
            "Epoch 66/150\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1298 - MSE: 0.1298 - val_loss: 0.1117 - val_MSE: 0.1117\n",
            "Epoch 67/150\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1275 - MSE: 0.1275 - val_loss: 0.1097 - val_MSE: 0.1097\n",
            "Epoch 68/150\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1251 - MSE: 0.1251 - val_loss: 0.1079 - val_MSE: 0.1079\n",
            "Epoch 69/150\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1229 - MSE: 0.1229 - val_loss: 0.1060 - val_MSE: 0.1060\n",
            "Epoch 70/150\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1207 - MSE: 0.1207 - val_loss: 0.1041 - val_MSE: 0.1041\n",
            "Epoch 71/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1184 - MSE: 0.1184 - val_loss: 0.1022 - val_MSE: 0.1022\n",
            "Epoch 72/150\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1162 - MSE: 0.1162 - val_loss: 0.1004 - val_MSE: 0.1004\n",
            "Epoch 73/150\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1141 - MSE: 0.1141 - val_loss: 0.0987 - val_MSE: 0.0987\n",
            "Epoch 74/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1121 - MSE: 0.1121 - val_loss: 0.0970 - val_MSE: 0.0970\n",
            "Epoch 75/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1100 - MSE: 0.1100 - val_loss: 0.0953 - val_MSE: 0.0953\n",
            "Epoch 76/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1079 - MSE: 0.1079 - val_loss: 0.0936 - val_MSE: 0.0936\n",
            "Epoch 77/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1059 - MSE: 0.1059 - val_loss: 0.0920 - val_MSE: 0.0920\n",
            "Epoch 78/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1039 - MSE: 0.1039 - val_loss: 0.0905 - val_MSE: 0.0905\n",
            "Epoch 79/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1021 - MSE: 0.1021 - val_loss: 0.0889 - val_MSE: 0.0889\n",
            "Epoch 80/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1002 - MSE: 0.1002 - val_loss: 0.0873 - val_MSE: 0.0873\n",
            "Epoch 81/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0984 - MSE: 0.0984 - val_loss: 0.0858 - val_MSE: 0.0858\n",
            "Epoch 82/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0965 - MSE: 0.0965 - val_loss: 0.0845 - val_MSE: 0.0845\n",
            "Epoch 83/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0949 - MSE: 0.0949 - val_loss: 0.0832 - val_MSE: 0.0832\n",
            "Epoch 84/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0933 - MSE: 0.0933 - val_loss: 0.0819 - val_MSE: 0.0819\n",
            "Epoch 85/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0918 - MSE: 0.0918 - val_loss: 0.0807 - val_MSE: 0.0807\n",
            "Epoch 86/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0904 - MSE: 0.0904 - val_loss: 0.0794 - val_MSE: 0.0794\n",
            "Epoch 87/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0889 - MSE: 0.0889 - val_loss: 0.0782 - val_MSE: 0.0782\n",
            "Epoch 88/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0876 - MSE: 0.0876 - val_loss: 0.0770 - val_MSE: 0.0770\n",
            "Epoch 89/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0862 - MSE: 0.0862 - val_loss: 0.0758 - val_MSE: 0.0758\n",
            "Epoch 90/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0849 - MSE: 0.0849 - val_loss: 0.0747 - val_MSE: 0.0747\n",
            "Epoch 91/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0834 - MSE: 0.0834 - val_loss: 0.0735 - val_MSE: 0.0735\n",
            "Epoch 92/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0821 - MSE: 0.0821 - val_loss: 0.0725 - val_MSE: 0.0725\n",
            "Epoch 93/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0807 - MSE: 0.0807 - val_loss: 0.0714 - val_MSE: 0.0714\n",
            "Epoch 94/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0794 - MSE: 0.0794 - val_loss: 0.0704 - val_MSE: 0.0704\n",
            "Epoch 95/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0781 - MSE: 0.0781 - val_loss: 0.0694 - val_MSE: 0.0694\n",
            "Epoch 96/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0769 - MSE: 0.0769 - val_loss: 0.0686 - val_MSE: 0.0686\n",
            "Epoch 97/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0759 - MSE: 0.0759 - val_loss: 0.0677 - val_MSE: 0.0677\n",
            "Epoch 98/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0746 - MSE: 0.0746 - val_loss: 0.0669 - val_MSE: 0.0669\n",
            "Epoch 99/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0735 - MSE: 0.0735 - val_loss: 0.0661 - val_MSE: 0.0661\n",
            "Epoch 100/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0725 - MSE: 0.0725 - val_loss: 0.0653 - val_MSE: 0.0653\n",
            "Epoch 101/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0715 - MSE: 0.0715 - val_loss: 0.0645 - val_MSE: 0.0645\n",
            "Epoch 102/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0706 - MSE: 0.0706 - val_loss: 0.0637 - val_MSE: 0.0637\n",
            "Epoch 103/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0697 - MSE: 0.0697 - val_loss: 0.0629 - val_MSE: 0.0629\n",
            "Epoch 104/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0687 - MSE: 0.0687 - val_loss: 0.0620 - val_MSE: 0.0620\n",
            "Epoch 105/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0679 - MSE: 0.0679 - val_loss: 0.0612 - val_MSE: 0.0612\n",
            "Epoch 106/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0670 - MSE: 0.0670 - val_loss: 0.0606 - val_MSE: 0.0606\n",
            "Epoch 107/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0659 - MSE: 0.0659 - val_loss: 0.0600 - val_MSE: 0.0600\n",
            "Epoch 108/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0651 - MSE: 0.0651 - val_loss: 0.0594 - val_MSE: 0.0594\n",
            "Epoch 109/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0643 - MSE: 0.0643 - val_loss: 0.0587 - val_MSE: 0.0587\n",
            "Epoch 110/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0635 - MSE: 0.0635 - val_loss: 0.0581 - val_MSE: 0.0581\n",
            "Epoch 111/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0627 - MSE: 0.0627 - val_loss: 0.0574 - val_MSE: 0.0574\n",
            "Epoch 112/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0619 - MSE: 0.0619 - val_loss: 0.0568 - val_MSE: 0.0568\n",
            "Epoch 113/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0613 - MSE: 0.0613 - val_loss: 0.0561 - val_MSE: 0.0561\n",
            "Epoch 114/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0607 - MSE: 0.0607 - val_loss: 0.0555 - val_MSE: 0.0555\n",
            "Epoch 115/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0601 - MSE: 0.0601 - val_loss: 0.0549 - val_MSE: 0.0549\n",
            "Epoch 116/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0594 - MSE: 0.0594 - val_loss: 0.0544 - val_MSE: 0.0544\n",
            "Epoch 117/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0588 - MSE: 0.0588 - val_loss: 0.0539 - val_MSE: 0.0539\n",
            "Epoch 118/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0583 - MSE: 0.0583 - val_loss: 0.0534 - val_MSE: 0.0534\n",
            "Epoch 119/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0577 - MSE: 0.0577 - val_loss: 0.0529 - val_MSE: 0.0529\n",
            "Epoch 120/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0571 - MSE: 0.0571 - val_loss: 0.0525 - val_MSE: 0.0525\n",
            "Epoch 121/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0564 - MSE: 0.0564 - val_loss: 0.0520 - val_MSE: 0.0520\n",
            "Epoch 122/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0557 - MSE: 0.0557 - val_loss: 0.0515 - val_MSE: 0.0515\n",
            "Epoch 123/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0552 - MSE: 0.0552 - val_loss: 0.0512 - val_MSE: 0.0512\n",
            "Epoch 124/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0545 - MSE: 0.0545 - val_loss: 0.0508 - val_MSE: 0.0508\n",
            "Epoch 125/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0540 - MSE: 0.0540 - val_loss: 0.0503 - val_MSE: 0.0503\n",
            "Epoch 126/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0535 - MSE: 0.0535 - val_loss: 0.0500 - val_MSE: 0.0500\n",
            "Epoch 127/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0529 - MSE: 0.0529 - val_loss: 0.0497 - val_MSE: 0.0497\n",
            "Epoch 128/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0525 - MSE: 0.0525 - val_loss: 0.0495 - val_MSE: 0.0495\n",
            "Epoch 129/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0521 - MSE: 0.0521 - val_loss: 0.0495 - val_MSE: 0.0495\n",
            "Epoch 130/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0517 - MSE: 0.0517 - val_loss: 0.0495 - val_MSE: 0.0495\n",
            "Epoch 131/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0514 - MSE: 0.0514 - val_loss: 0.0493 - val_MSE: 0.0493\n",
            "Epoch 132/150\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0510 - MSE: 0.0510 - val_loss: 0.0490 - val_MSE: 0.0490\n",
            "Epoch 133/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0506 - MSE: 0.0506 - val_loss: 0.0485 - val_MSE: 0.0485\n",
            "Epoch 134/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0502 - MSE: 0.0502 - val_loss: 0.0479 - val_MSE: 0.0479\n",
            "Epoch 135/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0498 - MSE: 0.0498 - val_loss: 0.0474 - val_MSE: 0.0474\n",
            "Epoch 136/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0494 - MSE: 0.0494 - val_loss: 0.0469 - val_MSE: 0.0469\n",
            "Epoch 137/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0490 - MSE: 0.0490 - val_loss: 0.0466 - val_MSE: 0.0466\n",
            "Epoch 138/150\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0486 - MSE: 0.0486 - val_loss: 0.0464 - val_MSE: 0.0464\n",
            "Epoch 139/150\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0482 - MSE: 0.0482 - val_loss: 0.0462 - val_MSE: 0.0462\n",
            "Epoch 140/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0478 - MSE: 0.0478 - val_loss: 0.0460 - val_MSE: 0.0460\n",
            "Epoch 141/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0475 - MSE: 0.0475 - val_loss: 0.0457 - val_MSE: 0.0457\n",
            "Epoch 142/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0472 - MSE: 0.0472 - val_loss: 0.0454 - val_MSE: 0.0454\n",
            "Epoch 143/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0469 - MSE: 0.0469 - val_loss: 0.0450 - val_MSE: 0.0450\n",
            "Epoch 144/150\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0466 - MSE: 0.0466 - val_loss: 0.0447 - val_MSE: 0.0447\n",
            "Epoch 145/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0463 - MSE: 0.0463 - val_loss: 0.0445 - val_MSE: 0.0445\n",
            "Epoch 146/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0460 - MSE: 0.0460 - val_loss: 0.0442 - val_MSE: 0.0442\n",
            "Epoch 147/150\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0457 - MSE: 0.0457 - val_loss: 0.0440 - val_MSE: 0.0440\n",
            "Epoch 148/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0455 - MSE: 0.0455 - val_loss: 0.0438 - val_MSE: 0.0438\n",
            "Epoch 149/150\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0452 - MSE: 0.0452 - val_loss: 0.0436 - val_MSE: 0.0436\n",
            "Epoch 150/150\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0450 - MSE: 0.0450 - val_loss: 0.0435 - val_MSE: 0.0435\n"
          ]
        }
      ],
      "source": [
        "# Train the model.\n",
        "# verbose = 0 means no output. verbose = 1 to view the epochs.\n",
        "history = my_model1.fit(X_model, Y_model, validation_data=(X_valid, Y_valid), epochs= 150,batch_size =64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "FNrSjFEIpmhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6172f7-21e2-4a33-c78c-510d19dbdc05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# View the keys.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GLXS6Xthpmhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e497905a-8328-420e-91e1-6fe7cc023672"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visualize the training history. \n",
        "n_skip = 100                 # Skip the first few steps.\n",
        "plt.plot(history.history['MSE'][n_skip:], c=\"b\")\n",
        "plt.plot(history.history['val_MSE'][n_skip:], c=\"g\")\n",
        "plt.title('Training History')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yKI9JU_pmht"
      },
      "source": [
        "#### 1.5. Testing: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFGevuL6pmht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d47d66-af4d-4795-b317-4dd9d6405684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Predict and test using a formula.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p05mQlvqpmhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b17fad-5684-4f3d-a259-4756649d20e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE : 5.64\n"
          ]
        }
      ],
      "source": [
        "# Use the evaluate() method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4hjzuQLpmh0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}